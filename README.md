# Nutrition Facts Vision (NFV) - Experimental Evaluation Framework

This repository contains the **benchmarking scripts, datasets, evaluation logic, and statistical analysis tools** developed for the research paper: *"Nutrition Facts Vision: An LLM-Powered Mobile System for Personalized Food Label Analysis and Risk Assessment."*

It serves as the scientific companion to the [NFV Mobile Application](https://github.com/ZiyaKolcu/nutrition-facts-vision-app), focusing strictly on the quantitative validation of the system's performance across different data quality conditions and Large Language Models (LLMs).

## ğŸ§ª Project Overview

The goal of this framework is to reproduce the experimental results presented in the paper, specifically testing two core hypotheses and validating the results statistically:

* **Hypothesis 1 (H1 - Data Extraction):** Evaluating the ability of LLMs to correct noisy OCR text and extract structured nutritional data (JSON) under different input conditions.
* **Hypothesis 2 (H2 - Clinical Reasoning):** Measuring the "Cascading Quality Effect"â€”how upstream OCR quality impacts downstream personalized risk assessment (Safety Recall & Precision).
* **Statistical Validation:** Rigorous pairwise comparison of models (Efficient vs. High-Reasoning) using non-parametric tests to confirm significance.

## ğŸ“‚ Repository Structure

The project is organized to isolate evaluation stages and statistical testing:

```bash
â”œâ”€â”€ app/services/nutrition/    # Core LLM Clients (OpenAI, Gemini, Claude) & Logic
â”œâ”€â”€ common/                    # Shared utilities for data loading and metric calculation
â”œâ”€â”€ hypothesis_1/              # Scripts & Data for Stage 1 Evaluation (OCR Correction)
â”‚   â”œâ”€â”€ merged_ground_truths.json  # 100% Human-verified reference dataset
â”‚   â”œâ”€â”€ run_h1.py                  # Script to execute Stage 1 benchmarks
â”‚   â””â”€â”€ evaluate_h1.py             # Script to calculate Precision/Recall/F1
â”œâ”€â”€ hypothesis_2/              # Scripts & Data for Stage 2 Evaluation (Risk Assessment)
â”‚   â”œâ”€â”€ profiles.json              # Deterministic logic for Synthetic Health Profiles
â”‚   â”œâ”€â”€ run_h2.py                  # Script to execute Stage 2 benchmarks
â”‚   â””â”€â”€ evaluate_h2.py             # Script to calculate Safety Recall & Conservative Precision
â”œâ”€â”€ statistical_test/          # NEW: Statistical significance & Error analysis
â”‚   â”œâ”€â”€ statistical_significance_test.py # Wilcoxon & Bootstrap analysis script
â”‚   â””â”€â”€ error_finder.py            # Utility to identify specific failure cases
â”œâ”€â”€ ocr texts/                 # Input Data Sources (Experimental Conditions)
â”‚   â”œâ”€â”€ raw_ocr_texts.json         # Condition 1: Baseline (Noisy On-Device OCR)
â”‚   â”œâ”€â”€ structured_ocr_texts.json  # Condition 2: Method A (Heuristic Grouping)
â”‚   â””â”€â”€ cloud_vision_ocr_texts.json# Condition 3: Method B (High-Fidelity Cloud OCR)
â””â”€â”€ requirements.txt           # Python dependencies

```

## âš™ï¸ Experimental Conditions

The framework evaluates performance across three distinct data quality tiers:

1. **Baseline:** Raw output from Google ML Kit (On-Device).
2. **Method A:** On-Device output processed with a custom geometric clustering heuristic.
3. **Method B:** Output from Google Cloud Vision API (Upper Bound).

## ğŸš€ Installation & Setup

1. **Clone the repository:**

```bash
git clone [https://github.com/ZiyaKolcu/nfv-experiment.git](https://github.com/ZiyaKolcu/nfv-experiment.git)
cd nfv-experiment

```

2. **Install dependencies:**

```bash
pip install -r requirements.txt

```

3. **Environment Configuration:**
Create a `.env` file in the root directory:

```env
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=AIza...
ANTHROPIC_API_KEY=sk-ant...

```

## ğŸ“Š Running the Experiments

### 1. Reproducing Stage 1 Results (OCR Correction)

To test how well models correct noisy text into structured JSON:

```bash
python hypothesis_1/run_h1.py

```

* **Output:** Generates raw JSON extractions in `hypothesis_1/results and evaluation/`.
* **Evaluation:** Run `evaluate_h1.py` afterward to compute F1 scores.

### 2. Reproducing Stage 2 Results (Risk Assessment)

To test the safety and reasoning capabilities of the models (dependent on H1 results):

```bash
python hypothesis_2/run_h2.py

```

* **Input:** Uses outputs from H1 to simulate the full pipeline.
* **Output:** Generates risk assessment logs in `hypothesis_2/results and evaluation/`.

### 3. Statistical Significance Analysis

To perform pairwise comparisons between "Efficient" (Flash/Haiku/Mini) and "High-Reasoning" (Pro/Sonnet/GPT-5.1) models:

```bash
python statistical_test/statistical_significance_test.py

```

**Methodology:**
This script executes the following for both H1 (Extraction) and H2 (Risk Assessment):

* **Wilcoxon Signed-Rank Test:** Non-parametric test for paired samples.
* **Bootstrap Confidence Intervals:** 10,000 resamples (CI=0.95) to estimate the stability of performance differences.
* **Output:** A console summary table and a CSV report (`statistical_significance_results.csv`) detailing p-values and significance levels (*** p<0.001).

**Model Pairs Tested:**

* **Anthropic:** Claude Haiku 4.5 vs. Claude Sonnet 4.5
* **Google:** Gemini 3 Flash vs. Gemini 3 Pro
* **OpenAI:** GPT-5-mini vs. GPT-5.1

## ğŸ§  Supported Models

The framework supports benchmarking the following model families:

* **OpenAI:** GPT-5-mini, GPT-5.1
* **Google:** Gemini 3 Flash, Gemini 3 Pro
* **Anthropic:** Claude 4.5 Haiku, Claude 4.5 Sonnet

## ğŸ“ Datasets & Ground Truth

* **`merged_ground_truths.json`**: Contains verbatim transcriptions and normalized nutritional values for 50 Turkish food products.
* **`profiles.json`**: Logic rules for synthetic health profiles (e.g., Type 2 Diabetic, Nut Allergy) used to validate risk assessment.

## ğŸ“„ Citation

If you use this code or dataset in your research, please cite:

```bibtex
@software{nfv_ocr_experiment,
  title={Nutrition Facts Vision: An LLM-Powered Mobile System for Personalized Food Label Analysis},
  author={Kolcu, Ziya},
  year={2025},
  url={[https://github.com/ZiyaKolcu/nfv_experiment_app](https://github.com/ZiyaKolcu/nfv_experiment_app)}
}

```

---

*This repository is intended for academic peer review and reproducibility purposes.*
